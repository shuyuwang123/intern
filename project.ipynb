{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2iixLlQ61tR",
        "outputId": "e88b9ce7-4390-48ed-af5a-489a3f89664e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "ç›˜å£æœ€å¤§æ¡£ä½: 5 æ¡£\n",
            "     MDDate     MDTime  SecurityType SecuritySubType SecurityID  \\\n",
            "0  20230103  092900200             8           08001       IC00   \n",
            "1  20230103  093000200             8           08001       IC00   \n",
            "2  20230103  093000700             8           08001       IC00   \n",
            "3  20230103  093001200             8           08001       IC00   \n",
            "4  20230103  093001700             8           08001       IC00   \n",
            "5  20230103  093002200             8           08001       IC00   \n",
            "6  20230103  093002700             8           08001       IC00   \n",
            "7  20230103  093003200             8           08001       IC00   \n",
            "8  20230103  093003700             8           08001       IC00   \n",
            "9  20230103  093004200             8           08001       IC00   \n",
            "\n",
            "   SecurityIDSource Symbol TradingPhaseCode  PreClosePx  NumTrades  \\\n",
            "0               301   IC00                3      5871.0        NaN   \n",
            "1               301   IC00                3      5871.0        NaN   \n",
            "2               301   IC00                3      5871.0        NaN   \n",
            "3               301   IC00                3      5871.0        NaN   \n",
            "4               301   IC00                3      5871.0        NaN   \n",
            "5               301   IC00                3      5871.0        NaN   \n",
            "6               301   IC00                3      5871.0        NaN   \n",
            "7               301   IC00                3      5871.0        NaN   \n",
            "8               301   IC00                3      5871.0        NaN   \n",
            "9               301   IC00                3      5871.0        NaN   \n",
            "\n",
            "   TotalVolumeTrade  TotalValueTrade  LastPx  OpenPx  ClosePx  HighPx   LowPx  \\\n",
            "0              17.0       19924000.0  5860.0  5860.0      NaN  5860.0  5860.0   \n",
            "1              22.0       25781160.0  5857.4  5860.0      NaN  5860.0  5856.0   \n",
            "2              33.0       38667960.0  5860.0  5860.0      NaN  5860.0  5856.0   \n",
            "3              45.0       52730720.0  5860.0  5860.0      NaN  5860.0  5856.0   \n",
            "4              63.0       73827560.0  5859.6  5860.0      NaN  5864.2  5856.0   \n",
            "5              64.0       74999960.0  5862.0  5860.0      NaN  5864.2  5856.0   \n",
            "6              81.0       94919000.0  5855.2  5860.0      NaN  5864.2  5855.2   \n",
            "7              86.0      100777080.0  5857.4  5860.0      NaN  5864.2  5855.2   \n",
            "8              99.0      116006440.0  5858.4  5860.0      NaN  5864.2  5855.2   \n",
            "9             112.0      131234520.0  5859.0  5860.0      NaN  5864.2  5855.2   \n",
            "\n",
            "    MaxPx   MinPx  OptionPosition TradingDate  PreOpenInterest  \\\n",
            "0  6461.8  5287.0             NaN    20230103         114121.0   \n",
            "1  6461.8  5287.0             NaN    20230103         114121.0   \n",
            "2  6461.8  5287.0             NaN    20230103         114121.0   \n",
            "3  6461.8  5287.0             NaN    20230103         114121.0   \n",
            "4  6461.8  5287.0             NaN    20230103         114121.0   \n",
            "5  6461.8  5287.0             NaN    20230103         114121.0   \n",
            "6  6461.8  5287.0             NaN    20230103         114121.0   \n",
            "7  6461.8  5287.0             NaN    20230103         114121.0   \n",
            "8  6461.8  5287.0             NaN    20230103         114121.0   \n",
            "9  6461.8  5287.0             NaN    20230103         114121.0   \n",
            "\n",
            "   PreSettlePrice  OpenInterest  SettlePrice  ReferencePrice  Buy1Price  \\\n",
            "0          5874.4      114116.0          NaN             NaN     5858.0   \n",
            "1          5874.4      114115.0          NaN             NaN     5855.0   \n",
            "2          5874.4      114109.0          NaN             NaN     5859.4   \n",
            "3          5874.4      114101.0          NaN             NaN     5857.4   \n",
            "4          5874.4      114090.0          NaN             NaN     5862.0   \n",
            "5          5874.4      114090.0          NaN             NaN     5858.0   \n",
            "6          5874.4      114088.0          NaN             NaN     5855.2   \n",
            "7          5874.4      114086.0          NaN             NaN     5857.4   \n",
            "8          5874.4      114078.0          NaN             NaN     5856.2   \n",
            "9          5874.4      114072.0          NaN             NaN     5856.4   \n",
            "\n",
            "   Buy1OrderQty  Sell1Price  Sell1OrderQty  Buy2Price  Buy2OrderQty  \\\n",
            "0           1.0      5864.6            4.0     5857.0           1.0   \n",
            "1           1.0      5857.4            4.0     5854.4           1.0   \n",
            "2           1.0      5860.0            5.0     5859.0           1.0   \n",
            "3           3.0      5859.4            1.0     5857.2           2.0   \n",
            "4           1.0      5864.0            1.0     5857.8           7.0   \n",
            "5           3.0      5862.0            3.0     5857.8           3.0   \n",
            "6           1.0      5861.4            3.0     5855.0           4.0   \n",
            "7           1.0      5860.0            2.0     5857.2           3.0   \n",
            "8           1.0      5859.6            1.0     5855.6           4.0   \n",
            "9           1.0      5859.4            3.0     5855.4           1.0   \n",
            "\n",
            "   Sell2Price  Sell2OrderQty  Buy3Price  Buy3OrderQty  Sell3Price  \\\n",
            "0      5869.2            2.0     5856.0           1.0      5869.4   \n",
            "1      5857.8            2.0     5853.0           1.0      5858.0   \n",
            "2      5862.0            5.0     5857.4           3.0      5863.0   \n",
            "3      5860.0            1.0     5855.4           7.0      5863.0   \n",
            "4      5864.2            5.0     5855.2           1.0      5864.4   \n",
            "5      5862.4            2.0     5857.6           1.0      5862.6   \n",
            "6      5861.6            3.0     5854.4           1.0      5861.8   \n",
            "7      5860.8            2.0     5857.0           2.0      5861.0   \n",
            "8      5859.8            5.0     5855.4           1.0      5860.0   \n",
            "9      5859.6            3.0     5855.2           1.0      5859.8   \n",
            "\n",
            "   Sell3OrderQty  Buy4Price  Buy4OrderQty  Sell4Price  Sell4OrderQty  \\\n",
            "0            1.0     5855.0           1.0      5869.8            1.0   \n",
            "1            4.0     5852.8           1.0      5858.4            3.0   \n",
            "2            2.0     5857.2           9.0      5864.2           16.0   \n",
            "3            2.0     5855.2           1.0      5864.2           16.0   \n",
            "4            1.0     5855.0           4.0      5865.0            1.0   \n",
            "5            3.0     5855.2           2.0      5862.8            1.0   \n",
            "6            5.0     5853.4           1.0      5862.0            4.0   \n",
            "7            1.0     5856.6           3.0      5861.2            5.0   \n",
            "8            1.0     5855.2           1.0      5860.8            1.0   \n",
            "9            1.0     5855.0           4.0      5860.0            1.0   \n",
            "\n",
            "   Buy5Price  Buy5OrderQty  Sell5Price  Sell5OrderQty HTSCSecurityID  \\\n",
            "0     5854.4           1.0      5870.0            3.0        IC00.CF   \n",
            "1     5852.2           1.0      5862.0            1.0        IC00.CF   \n",
            "2     5856.8           1.0      5864.4            1.0        IC00.CF   \n",
            "3     5855.0           4.0      5864.4            1.0        IC00.CF   \n",
            "4     5854.4           1.0      5865.6            1.0        IC00.CF   \n",
            "5     5855.0           4.0      5863.0            3.0        IC00.CF   \n",
            "6     5852.8           1.0      5863.8            2.0        IC00.CF   \n",
            "7     5856.4           1.0      5861.4            4.0        IC00.CF   \n",
            "8     5855.0           4.0      5861.2            1.0        IC00.CF   \n",
            "9     5854.4           1.0      5860.8            1.0        IC00.CF   \n",
            "\n",
            "     ReceiveDateTime  ChannelNo   month  \n",
            "0  20230103092900375        NaN  202301  \n",
            "1  20230103093000350        NaN  202301  \n",
            "2  20230103093000865        NaN  202301  \n",
            "3  20230103093001338        NaN  202301  \n",
            "4  20230103093001842        NaN  202301  \n",
            "5  20230103093002342        NaN  202301  \n",
            "6  20230103093002831        NaN  202301  \n",
            "7  20230103093003333        NaN  202301  \n",
            "8  20230103093003838        NaN  202301  \n",
            "9  20230103093004336        NaN  202301  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip -q install lightgbm==4.3.0 pyarrow tqdm\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "import os, gc, warnings, numpy as np, pyarrow.parquet as pq, lightgbm as lgb, tqdm\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "BASE_PATH   = \"/content/drive/My Drive/\"            # GDrive root\n",
        "FILE        = \"IC00_20230101_20241231.parquet\"      # Parquet file name\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "pf   = pq.ParquetFile(os.path.join(BASE_PATH, FILE))\n",
        "cols = pf.schema.names\n",
        "\n",
        "\n",
        "max_lvl = max(i for i in range(1, 11) if f\"Buy{i}Price\" in cols)\n",
        "print(f\"ç›˜å£æœ€å¤§æ¡£ä½: {max_lvl} æ¡£\")\n",
        "\n",
        "# è¯»å–å®Œæ•´Parquetæ–‡ä»¶\n",
        "table   = pf.read()\n",
        "full_df = table.to_pandas()\n",
        "\n",
        "# å–æ¶ˆPandasæ˜¾ç¤ºé™åˆ¶\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "\n",
        "print(full_df.head(10))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # å°†MDTimeè½¬æ¢ä¸ºæ¯«ç§’æ—¶é—´æˆ³ï¼ˆä»å½“æ—¥0ç‚¹å¼€å§‹çš„æ€»æ¯«ç§’æ•°ï¼‰\n",
        "# def mdtime_to_ms(mdtime):\n",
        "#     s = str(int(mdtime)).zfill(9)\n",
        "#     hours = int(s[:2])\n",
        "#     minutes = int(s[2:4])\n",
        "#     seconds = int(s[4:6])\n",
        "#     millis = int(s[6:9])\n",
        "#     return (hours * 3600 + minutes * 60 + seconds) * 1000 + millis\n",
        "\n",
        "# # åº”ç”¨è½¬æ¢å‡½æ•°\n",
        "# full_df['time_ms'] = full_df['MDTime'].apply(mdtime_to_ms)\n",
        "\n",
        "# # å®šä¹‰è¿ç»­ç«ä»·æ—¶é—´æ®µï¼ˆæ¯«ç§’è¡¨ç¤ºï¼‰\n",
        "# MORNING_START = 9 * 3600 * 1000 + 30 * 60 * 1000  # 09:30:00.000\n",
        "# MORNING_END = 11 * 3600 * 1000 + 30 * 60 * 1000   # 11:30:00.000\n",
        "# AFTERNOON_START = 13 * 3600 * 1000                 # 13:00:00.000\n",
        "# AFTERNOON_END = 14 * 3600 * 1000 + 57 * 60 * 1000  # 14:57:00.000\n",
        "\n",
        "# # # ç­›é€‰è¿ç»­ç«ä»·æ•°æ®ï¼ˆæ’é™¤é›†åˆç«ä»·å’Œæ”¶ç›˜é›†åˆç«ä»·ï¼‰\n",
        "# # continuous_mask = (\n",
        "# #     ((full_df['time_ms'] >= MORNING_START) & (full_df['time_ms'] <= MORNING_END)) |\n",
        "# #     ((full_df['time_ms'] >= AFTERNOON_START) & (full_df['time_ms'] < AFTERNOON_END))\n",
        "\n",
        "# # continuous_df = full_df[continuous_mask].copy()\n",
        "\n",
        "# # æŒ‰æ—¥æœŸæ’åº\n",
        "# continuous_df = continuous_df.sort_values(['MDDate', 'time_ms'])\n",
        "\n",
        "# # è®¡ç®—æ—¶é—´é—´éš”ï¼ˆæ¯«ç§’ï¼‰\n",
        "# continuous_df['prev_time_ms'] = continuous_df.groupby('MDDate')['time_ms'].shift(1)\n",
        "# continuous_df['time_diff_ms'] = continuous_df['time_ms'] - continuous_df['prev_time_ms']\n",
        "\n",
        "# # ç§»é™¤æ— æ•ˆè¡Œï¼ˆé¦–è¡Œå’Œè·¨å¤©è¡Œï¼‰\n",
        "# continuous_df = continuous_df.dropna(subset=['time_diff_ms'])\n",
        "# continuous_df = continuous_df[continuous_df['time_diff_ms'] > 0]  # ç§»é™¤è´Ÿé—´éš”ï¼ˆè·¨å¤©ï¼‰\n",
        "\n",
        "# # ç»Ÿè®¡é—´éš”åˆ†å¸ƒ\n",
        "# interval_stats = continuous_df['time_diff_ms'].value_counts().sort_index()\n",
        "# total_intervals = len(continuous_df)\n",
        "# non_500ms = continuous_df[continuous_df['time_diff_ms'] != 500]\n",
        "# non_500ms_ratio = len(non_500ms) / total_intervals * 100\n",
        "\n",
        "# print(f\"ã€è¿ç»­ç«ä»·é˜¶æ®µç»Ÿè®¡ã€‘\")\n",
        "# print(f\"æ€»è®°å½•æ•°: {len(full_df):,} | è¿ç»­ç«ä»·è®°å½•æ•°: {len(continuous_df):,}\")\n",
        "# print(f\"500msé—´éš”å æ¯”: {100 - non_500ms_ratio:.2f}%\")\n",
        "# print(f\"é500msé—´éš”å æ¯”: {non_500ms_ratio:.2f}%\")\n",
        "# print(\"\\né—´éš”åˆ†å¸ƒï¼ˆæ¯«ç§’ï¼‰:\")\n",
        "# print(interval_stats.head(10).to_string())\n",
        "\n",
        "\n",
        "# # è¾“å‡ºå¼‚å¸¸é—´éš”æ ·ä¾‹\n",
        "# if not non_500ms.empty:\n",
        "#     print(\"\\nã€é500msé—´éš”æ ·ä¾‹ã€‘\")\n",
        "#     sample = non_500ms[['MDDate', 'MDTime', 'time_diff_ms']].head(10).copy()\n",
        "\n",
        "#     # æ·»åŠ å¯è¯»æ—¶é—´æ ¼å¼\n",
        "#     sample['time_str'] = sample['MDTime'].apply(\n",
        "#         lambda x: f\"{str(x).zfill(9)[:2]}:{str(x).zfill(9)[2:4]}:{str(x).zfill(9)[4:6]}.{str(x).zfill(9)[6:]}\")\n",
        "\n",
        "#     print(sample[['MDDate', 'time_str', 'time_diff_ms']].to_string(index=False))"
      ],
      "metadata": {
        "id": "kURFCcTrBKf4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "!pip -q install lightgbm==4.3.0 pyarrow tqdm\n",
        "\n",
        "import os, gc, warnings, numpy as np, pyarrow.parquet as pq, lightgbm as lgb, tqdm\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from google.colab import drive\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "GDRIVE_ROOT   = \"/content/drive/My Drive/\"\n",
        "PARQUET_FILE  = \"IC00_20230101_20241231.parquet\"\n",
        "WINDOW_SIZE   = 1_000        # rows to look back (tâ€‘999 â€¦ t)\n",
        "HORIZON       = 500          # rows ahead to predict (t+500)\n",
        "STRIDE        = 250          # step for selecting t (1 â‡’ every row)\n",
        "THRESH        = 0.002        # label threshold (relative Î”)\n",
        "SEED          = 42\n",
        "VAL_SPLIT     = 0.10\n",
        "N_ESTIM       = 2_000\n",
        "LR            = 0.05\n",
        "EARLY_STOP    = 200\n",
        "np.random.seed(SEED)\n",
        "\n",
        "\n",
        "print(\"â–¶ Mounting GoogleÂ Drive â€¦\")\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "print(\" é˜…è¯»ä¸­ â€¦\")\n",
        "pf   = pq.ParquetFile(os.path.join(GDRIVE_ROOT, PARQUET_FILE))\n",
        "cols = pf.schema.names\n",
        "DEPTH = max(i for i in range(1, 11) if f\"Buy{i}Price\" in cols)\n",
        "\n",
        "buy_p_cols  = [f\"Buy{i}Price\"     for i in range(1, DEPTH + 1)]\n",
        "sell_p_cols = [f\"Sell{i}Price\"    for i in range(1, DEPTH + 1)]\n",
        "buy_q_cols  = [f\"Buy{i}OrderQty\"  for i in range(1, DEPTH + 1)]\n",
        "sell_q_cols = [f\"Sell{i}OrderQty\" for i in range(1, DEPTH + 1)]\n",
        "extra_cols  = [\"Buy1Price\", \"Sell1Price\"]\n",
        "\n",
        "arrow_tbl = pf.read(columns=extra_cols + buy_p_cols + sell_p_cols + buy_q_cols + sell_q_cols)\n",
        "N_ROWS     = arrow_tbl.num_rows\n",
        "print(f\"   rows: {N_ROWS}   depth: {DEPTH}\")\n",
        "\n",
        "# ç”¨float32\n",
        "_to_np = lambda c: arrow_tbl.column(c).to_numpy(zero_copy_only=False).astype(np.float32)\n",
        "\n",
        "buy_p_np  = np.column_stack([_to_np(c) for c in buy_p_cols ])\n",
        "sell_p_np = np.column_stack([_to_np(c) for c in sell_p_cols])\n",
        "buy_q_np  = np.column_stack([_to_np(c) for c in buy_q_cols ])\n",
        "sell_q_np = np.column_stack([_to_np(c) for c in sell_q_cols])\n",
        "buy1_np   = _to_np(\"Buy1Price\")\n",
        "sell1_np  = _to_np(\"Sell1Price\")\n",
        "\n",
        "# å†…å­˜åˆ é™¤\n",
        "del arrow_tbl; gc.collect()\n",
        "\n",
        "# --------------------  ç”Ÿå‡ºyï¼Œå¹¶å‚¨å­˜åœ¨ labels arrayé‡Œ--------------------\n",
        "mid_price = (buy1_np + sell1_np) * 0.5\n",
        "\n",
        "first_t   = WINDOW_SIZE - 1\n",
        "last_t    = N_ROWS - HORIZON - 1\n",
        "all_t     = np.arange(first_t, last_t + 1, STRIDE, dtype=np.int32)\n",
        "\n",
        "delta_mid = (mid_price[all_t + HORIZON] - mid_price[all_t]) / mid_price[all_t]\n",
        "labels    = np.zeros_like(delta_mid, np.int8)\n",
        "labels[delta_mid >  THRESH] = 2\n",
        "labels[delta_mid < -THRESH] = 0\n",
        "labels[np.abs(delta_mid) <= THRESH] = 1\n",
        "print(\"   labels computed:\", len(labels))\n",
        "\n",
        "# -------------------- é«˜é¢‘å› å­ï¼ˆæ ¹æ®ç ”æŠ¥ï¼‰ --------------------\n",
        "\n",
        "def extract_feat(t: int) -> np.ndarray:\n",
        "    s = t - WINDOW_SIZE + 1\n",
        "    ask_p = sell_p_np[s:t+1]\n",
        "    bid_p = buy_p_np [s:t+1]\n",
        "    ask_q = sell_q_np[s:t+1]\n",
        "    # è¡¨ç¤ºä» s åˆ° tï¼ˆåŒ…æ‹¬ tï¼‰ã€‚\n",
        "    bid_q = buy_q_np [s:t+1]\n",
        "    ask_last, bid_last = ask_p[-1], bid_p[-1]\n",
        "\n",
        "    feat = []\n",
        "    # v1 snapshot (prices & sizes at t)\n",
        "    feat.extend(ask_last)\n",
        "    feat.extend(bid_last)\n",
        "    feat.extend(ask_q[-1])\n",
        "    feat.extend(bid_q[-1])\n",
        "    # v2 spread & mid at t\n",
        "    feat.extend(ask_last - bid_last)\n",
        "    feat.extend((ask_last + bid_last) * 0.5)\n",
        "    # v3 average |Î”| over window\n",
        "    feat.extend(np.abs(np.diff(ask_p, axis=0)).mean(axis=0))\n",
        "    feat.extend(np.abs(np.diff(bid_p, axis=0)).mean(axis=0))\n",
        "    # v4 window means\n",
        "    feat.append(ask_p.mean())\n",
        "    feat.append(bid_p.mean())\n",
        "    feat.append(ask_q.mean())\n",
        "    feat.append(bid_q.mean())\n",
        "    # v5 imbalance sums\n",
        "    feat.append((ask_p - bid_p).sum())\n",
        "    feat.append((ask_q - bid_q).sum())\n",
        "    # v6 slopes\n",
        "    feat.extend((ask_last - ask_p[0]) / (WINDOW_SIZE - 1))\n",
        "    feat.extend((bid_last - bid_p[0]) / (WINDOW_SIZE - 1))\n",
        "    feat.extend((ask_q[-1] - ask_q[0]) / (WINDOW_SIZE - 1))\n",
        "    feat.extend((bid_q[-1] - bid_q[0]) / (WINDOW_SIZE - 1))\n",
        "    return np.asarray(feat, np.float32)\n",
        "\n",
        "print(\"â–¶ Extracting features â€¦\")\n",
        "X_all = np.stack([extract_feat(t) for t in tqdm.tqdm(all_t)])\n",
        "print(\"   X:\", X_all.shape, \" y:\", labels.shape)\n",
        "\n",
        "# # -------------------- è®­ç»ƒæµ‹è¯•åˆ†å‰² --------------------\n",
        "# num_total = len(all_t)\n",
        "# train_end = int(num_total * 0.8)\n",
        "# val_end   = int(num_total * 0.9)\n",
        "\n",
        "# X_train, y_train = X_all[:train_end], labels[:train_end]\n",
        "# X_val,   y_val   = X_all[train_end:val_end], labels[train_end:val_end]\n",
        "# X_test,  y_test  = X_all[val_end:], labels[val_end:]\n",
        "# print(f\"split: Train {len(X_train)} | Val {len(X_val)} | Test {len(X_test)}\")\n",
        "\n",
        "\n",
        "# --------------------  (è®­ç»ƒæµ‹è¯•) --------------------\n",
        "SAFE_GAP = 1_000          # å¯ä»¥æ”¹æˆ 0ã€HORIZON æˆ– WINDOW_SIZE+HORIZON-1ï¼Œç›®å‰å…ˆè®¾ç½®æˆ1000\n",
        "\n",
        "num_total = len(all_t)\n",
        "\n",
        "# â€”â€” è®¡ç®—èµ·æ­¢ç´¢å¼•â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "train_start_idx = 0\n",
        "train_end_idx   = int(num_total * 0.8) - 1\n",
        "\n",
        "valid_start_idx = train_end_idx + SAFE_GAP + 1\n",
        "valid_end_idx   = int(num_total * 0.9) - 1\n",
        "\n",
        "test_start_idx  = valid_end_idx + SAFE_GAP + 1\n",
        "# -------------------------------------------------------------\n",
        "\n",
        "# â€”â€” å®é™…åˆ‡ç‰‡â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
        "X_train, y_train = X_all[train_start_idx:train_end_idx+1],          labels[train_start_idx:train_end_idx+1]\n",
        "X_val,   y_val   = X_all[valid_start_idx:valid_end_idx+1],          labels[valid_start_idx:valid_end_idx+1]\n",
        "X_test,  y_test  = X_all[test_start_idx:   ],                       labels[test_start_idx:   ]\n",
        "\n",
        "\n",
        "\n",
        "# -------------------- Class weightsæ‰“å° ä»¤è®­ç»ƒé›†ä¸­æ•°é‡æœ€å¤šçš„ç±»åˆ«æƒé‡ä¸º 1ã€‚\n",
        "# å…¶ä»–ç±»åˆ«çš„æƒé‡æ˜¯æŒ‰ç…§â€œå¤šå°‘å€æ›´ç¨€å°‘â€ç»™çš„ã€‚\n",
        "\n",
        "cls, cnt = np.unique(y_train, return_counts=True)\n",
        "max_cnt  = cnt.max()\n",
        "weights  = np.asarray([max_cnt / dict(zip(cls, cnt))[c] for c in y_train], np.float32)\n",
        "print(\"   class_weight:\", {int(c): float(max_cnt/n) for c, n in zip(cls, cnt)})\n",
        "\n",
        "# -------------------- LightGBM --------------------\n",
        "train_ds = lgb.Dataset(X_train, y_train, weight=weights, free_raw_data=False)\n",
        "val_ds   = lgb.Dataset(X_val,   y_val,                free_raw_data=False)\n",
        "\n",
        "params = dict(\n",
        "    objective        = \"multiclass\",\n",
        "    num_class        = 3,\n",
        "    seed             = SEED,\n",
        "    learning_rate    = LR,\n",
        "    num_leaves       = 127,\n",
        "    max_depth        = -1,\n",
        "    feature_fraction = 0.9,\n",
        "    bagging_fraction = 0.9,\n",
        "    bagging_freq     = 5,\n",
        "    metric           = [\"multi_logloss\", \"multi_error\"],\n",
        "    min_gain_to_split= 1e-3,\n",
        ")\n",
        "\n",
        "print(\"â–¶ Training LightGBM â€¦\")\n",
        "model = lgb.train(\n",
        "    params,\n",
        "    train_ds,\n",
        "    num_boost_round = N_ESTIM,\n",
        "    valid_sets      = [train_ds, val_ds],\n",
        "    valid_names     = [\"train\", \"val\"],\n",
        "    callbacks       = [\n",
        "        lgb.log_evaluation(200),\n",
        "        lgb.early_stopping(EARLY_STOP)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# -------------------- Evaluation --------------------\n",
        "y_pred = model.predict(X_test, num_iteration=model.best_iteration).argmax(1)\n",
        "acc    = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nğŸŸ¢  Test Accuracy = {acc:.4f}\\n\")\n",
        "print(classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "# --------------------  Save --------------------\n",
        "model_path = \"/content/lgb_ic00_win1000_hor1000.txt\"\n",
        "model.save_model(model_path)\n",
        "print(\"model saved to\", model_path)\n"
      ],
      "metadata": {
        "id": "SvAA3W_l7LL0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13b1ad67-6d66-4797-a1ce-2dfa55f08a67"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â–¶ Mounting GoogleÂ Drive â€¦\n",
            "Mounted at /content/drive\n",
            " é˜…è¯»ä¸­ â€¦\n",
            "   rows: 12060324   depth: 5\n",
            "   labels computed: 48236\n",
            "â–¶ Extracting features â€¦\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48236/48236 [00:08<00:00, 5433.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   X: (48236, 66)  y: (48236,)\n",
            "   class_weight: {0: 13.43525179856115, 1: 1.0, 2: 13.603804127883448}\n",
            "â–¶ Training LightGBM â€¦\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007942 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 12060\n",
            "[LightGBM] [Info] Number of data points in the train set: 38588, number of used features: 66\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[200]\ttrain's multi_logloss: 0.224265\ttrain's multi_error: 0.0138232\tval's multi_logloss: 1.0214\tval's multi_error: 0.463912\n",
            "[400]\ttrain's multi_logloss: 0.0705171\ttrain's multi_error: 0.000416481\tval's multi_logloss: 0.997873\tval's multi_error: 0.394613\n",
            "Early stopping, best iteration is:\n",
            "[299]\ttrain's multi_logloss: 0.124862\ttrain's multi_error: 0.00348059\tval's multi_logloss: 0.981387\tval's multi_error: 0.415272\n",
            "\n",
            "ğŸŸ¢  Test Accuracy = 0.7626\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.2188    0.0680    0.1037       412\n",
            "           1     0.7976    0.9529    0.8683      3014\n",
            "           2     0.1684    0.0402    0.0649       398\n",
            "\n",
            "    accuracy                         0.7626      3824\n",
            "   macro avg     0.3949    0.3537    0.3456      3824\n",
            "weighted avg     0.6697    0.7626    0.7023      3824\n",
            "\n",
            "model saved to /content/lgb_ic00_win1000_hor1000.txt\n"
          ]
        }
      ]
    }
  ]
}